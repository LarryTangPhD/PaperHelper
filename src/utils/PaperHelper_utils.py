from langchain.prompts import ChatPromptTemplate
from langchain_openai.chat_models.base import BaseChatOpenAI
import os
import json
import random
import hashlib
import time
from functools import lru_cache
from typing import Optional, Dict, Any

# ä»ç¯å¢ƒå˜é‡ä¸­è·å– API Key - ä¼˜å…ˆä½¿ç”¨é€šä¹‰åƒé—®
api_key = os.getenv("DASHSCOPE_API_KEY") or os.getenv("DEEPSEEK_API_KEY")

# æ£€æŸ¥ API Key æ˜¯å¦è®¾ç½®
if not api_key:
    raise ValueError("è¯·è®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡ï¼ˆé€šä¹‰åƒé—®ï¼‰æˆ– DEEPSEEK_API_KEY ç¯å¢ƒå˜é‡")

# å®šä¹‰ base_url - ä½¿ç”¨å…¼å®¹æ¨¡å¼ï¼ˆå‚è€ƒæ•°çœ¸å¹³å°é…ç½®ï¼‰
base_url = "https://dashscope.aliyuncs.com/compatible-mode/v1"

# ç¼“å­˜æœºåˆ¶
_cache = {}

def _generate_cache_key(func_name: str, *args, **kwargs) -> str:
    """ç”Ÿæˆç¼“å­˜é”®"""
    args_str = str(args) + str(sorted(kwargs.items()))
    return hashlib.md5(f"{func_name}:{args_str}".encode()).hexdigest()

def _get_cached_result(cache_key: str) -> Optional[str]:
    """è·å–ç¼“å­˜ç»“æœ"""
    return _cache.get(cache_key)

def _set_cached_result(cache_key: str, result: str):
    """è®¾ç½®ç¼“å­˜ç»“æœ"""
    _cache[cache_key] = result

def _retry_with_backoff(func, max_retries=3, base_delay=1):
    """
    å¸¦é€€é¿çš„é‡è¯•æœºåˆ¶
    
    Args:
        func: è¦é‡è¯•çš„å‡½æ•°
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        base_delay: åŸºç¡€å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
    """
    for attempt in range(max_retries):
        try:
            return func()
        except Exception as e:
            if attempt == max_retries - 1:
                raise e
            
            # æŒ‡æ•°é€€é¿
            delay = base_delay * (2 ** attempt) + random.uniform(0, 1)
            print(f"è¯·æ±‚å¤±è´¥ï¼Œ{delay:.1f}ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
            time.sleep(delay)

# åˆ›å»º BaseChatOpenAI å®ä¾‹ - ä¼˜åŒ–é…ç½®ï¼ˆå‚è€ƒæ•°çœ¸å¹³å°ï¼‰
def get_llm(temperature=0.3, model_type="turbo"):
    """
    è·å–LLMå®ä¾‹ - ä¼˜åŒ–ç‰ˆé…ç½®
    
    Args:
        temperature: åˆ›é€ æ€§å‚æ•°ï¼ˆé»˜è®¤0.3ï¼Œæé«˜å“åº”é€Ÿåº¦ï¼‰
        model_type: æ¨¡å‹ç±»å‹ ("turbo" å¿«é€Ÿå“åº”, "plus" é«˜è´¨é‡)
    """
    # å°è¯•ä½¿ç”¨å¿«é€Ÿæ¨¡å‹ç®¡ç†å™¨
    try:
        from src.config.fast_llm_manager import fast_llm_manager
        return fast_llm_manager.get_llm(temperature)
    except ImportError:
        # å›é€€åˆ°é€šä¹‰åƒé—®æ¨¡å‹ - ä¼˜åŒ–é…ç½®
        model_name = "qwen-turbo" if model_type == "turbo" else "qwen-plus"
        return BaseChatOpenAI(
            model=model_name,
            openai_api_key=api_key,
            openai_api_base=base_url,
            temperature=temperature,
            max_tokens=1500,      # ä¼˜åŒ–tokenæ•°é‡
            timeout=30,           # å‡å°‘è¶…æ—¶æ—¶é—´
            request_timeout=30    # å‡å°‘è¯·æ±‚è¶…æ—¶æ—¶é—´
        )

# å…¨å±€å®ä¾‹ä½¿ç”¨é»˜è®¤temperature
llm = get_llm()

def generate_paper(subject, word_count, creativity):
    """ç”Ÿæˆè®ºæ–‡é€‰é¢˜å’Œå»ºè®® - ä¼˜åŒ–ç‰ˆï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    # ç”Ÿæˆç¼“å­˜é”®
    cache_key = _generate_cache_key("generate_paper", subject, word_count, creativity)
    
    # æ£€æŸ¥ç¼“å­˜
    cached_result = _get_cached_result(cache_key)
    if cached_result:
        try:
            result = json.loads(cached_result)
            return result.get('title'), result.get('abstract'), result.get('outline')
        except:
            pass
    
    # æ ¹æ®creativityé€‰æ‹©æ¨¡å‹ç±»å‹
    model_type = "plus" if creativity > 0.5 else "turbo"
    current_llm = get_llm(temperature=creativity, model_type=model_type)
    
    title_template = ChatPromptTemplate.from_messages([
        ("human", """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ–°é—»ä¼ æ’­å­¦æ•™æˆï¼Œå…·æœ‰ä¸°å¯Œçš„è®ºæ–‡æŒ‡å¯¼ç»éªŒã€‚è¯·ä¸ºä»¥ä¸‹ç ”ç©¶ä¸»é¢˜æä¾›é«˜è´¨é‡çš„è®ºæ–‡é€‰é¢˜å»ºè®®ã€‚

ç ”ç©¶ä¸»é¢˜ï¼š{subject}

è¯·ä»æ–°é—»ä¼ æ’­å­¦çš„ä¸“ä¸šè§’åº¦ï¼Œä¸ºè¯¥ä¸»é¢˜è®¾è®¡3-5ä¸ªå…·æœ‰å­¦æœ¯ä»·å€¼å’Œåˆ›æ–°æ€§çš„è®ºæ–‡é¢˜ç›®ã€‚æ¯ä¸ªé¢˜ç›®åº”è¯¥ï¼š
1. ç¬¦åˆæ–°é—»ä¼ æ’­å­¦çš„ç ”ç©¶èŒƒå¼
2. å…·æœ‰æ˜ç¡®çš„ç ”ç©¶é—®é¢˜å’Œç†è®ºæ„ä¹‰
3. ä½“ç°å½“å‰å­¦ç§‘å‘å±•è¶‹åŠ¿
4. é€‚åˆ{word_count}ä¸‡å­—çš„è®ºæ–‡ç¯‡å¹…

è¯·ç›´æ¥è¿”å›é¢˜ç›®åˆ—è¡¨ï¼Œæ¯ä¸ªé¢˜ç›®ä¸€è¡Œã€‚""")
    ])
    
    abstract_template = ChatPromptTemplate.from_messages([
        ("human", """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ–°é—»ä¼ æ’­å­¦æ•™æˆï¼Œè¯·ä¸ºä»¥ä¸‹è®ºæ–‡é¢˜ç›®æä¾›è¯¦ç»†çš„ç ”ç©¶å»ºè®®ã€‚

è®ºæ–‡é¢˜ç›®ï¼š{title}
é¢„æœŸç¯‡å¹…ï¼š{word_count}ä¸‡å­—

è¯·æä¾›ä»¥ä¸‹å†…å®¹ï¼š

1. **ç ”ç©¶æ„ä¹‰ä¸åˆ›æ–°ç‚¹**ï¼ˆ300å­—ä»¥å†…ï¼‰
   - ç†è®ºæ„ä¹‰
   - å®è·µæ„ä¹‰
   - åˆ›æ–°ç‚¹åˆ†æ

2. **ç ”ç©¶å¤§çº²è®¾è®¡**ï¼ˆ500å­—ä»¥å†…ï¼‰
   - å‰è¨€/å¼•è¨€
   - æ–‡çŒ®ç»¼è¿°
   - ç†è®ºæ¡†æ¶
   - ç ”ç©¶æ–¹æ³•
   - ç ”ç©¶ç»“æœ
   - è®¨è®º
   - ç»“è®º

3. **ç ”ç©¶å»ºè®®**ï¼ˆ200å­—ä»¥å†…ï¼‰
   - ç ”ç©¶è¿‡ç¨‹ä¸­éœ€è¦æ³¨æ„çš„é—®é¢˜
   - å¯èƒ½é‡åˆ°çš„å›°éš¾åŠè§£å†³æ–¹æ¡ˆ
   - å¯¹ç ”ç©¶è€…çš„å»ºè®®

è¯·ç¡®ä¿å†…å®¹ä¸“ä¸šã€å…·ä½“ã€å¯æ“ä½œï¼Œç¬¦åˆæ–°é—»ä¼ æ’­å­¦å­¦æœ¯è§„èŒƒã€‚""")
    ])

    # ä½¿ç”¨ç‰¹å®štemperatureçš„llm
    title_chain = title_template | current_llm
    abstract_chain = abstract_template | current_llm

    try:
        # ä½¿ç”¨é‡è¯•æœºåˆ¶è·å–æ ‡é¢˜
        def get_title():
            return title_chain.invoke({"subject": subject, "word_count": word_count}).content
        
        def get_abstract():
            return abstract_chain.invoke({
                "title": title, 
                "word_count": word_count
            }).content
        
        # è·å–æ ‡é¢˜
        title = _retry_with_backoff(get_title)
        
        # ç”Ÿæˆæ‘˜è¦å’Œç ”ç©¶å»ºè®®
        abstract = _retry_with_backoff(get_abstract)
        
        # ç¼“å­˜ç»“æœ
        result = {
            'title': title,
            'abstract': abstract,
            'outline': None
        }
        _set_cached_result(cache_key, json.dumps(result, ensure_ascii=False))
        
        return title, abstract, None
    except Exception as e:
        print(f"ç”Ÿæˆè®ºæ–‡å†…å®¹æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return None, None, None

def topic_diagnosis(topic, research_type):
    """é€‰é¢˜è¯Šæ–­åˆ†æ"""
    current_llm = get_llm(temperature=0.3)
    
    diagnosis_template = ChatPromptTemplate.from_messages([
        ("human", """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ–°é—»ä¼ æ’­å­¦æ•™æˆï¼Œè¯·å¯¹ä»¥ä¸‹é€‰é¢˜è¿›è¡Œä¸“ä¸šè¯Šæ–­ã€‚

ç ”ç©¶ä¸»é¢˜ï¼š{topic}
ç ”ç©¶ç±»å‹ï¼š{research_type}

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œè¯Šæ–­åˆ†æï¼š

1. **é€‰é¢˜ä»·å€¼è¯„ä¼°**
   - ç†è®ºè´¡çŒ®åº¦
   - å®è·µæ„ä¹‰
   - ç¤¾ä¼šä»·å€¼

2. **ç ”ç©¶å¯è¡Œæ€§åˆ†æ**
   - ç†è®ºå¯è¡Œæ€§
   - æ–¹æ³•å¯è¡Œæ€§
   - æ•°æ®å¯è·å¾—æ€§
   - æ—¶é—´å¯è¡Œæ€§

3. **åˆ›æ–°æ€§è¯„ä¼°**
   - ä¸ç°æœ‰ç ”ç©¶çš„åŒºåˆ«
   - åˆ›æ–°ç‚¹è¯†åˆ«
   - ç ”ç©¶ç©ºç™½å¡«è¡¥

4. **é£é™©è¯„ä¼°**
   - å¯èƒ½é‡åˆ°çš„å›°éš¾
   - ç ”ç©¶å±€é™æ€§
   - å»ºè®®çš„åº”å¯¹ç­–ç•¥

è¯·æä¾›è¯¦ç»†çš„åˆ†ææŠ¥å‘Šï¼Œç¡®ä¿ä¸“ä¸šã€å®¢è§‚ã€å…·ä½“ã€‚""")
    ])
    
    diagnosis_chain = diagnosis_template | current_llm
    
    try:
        result = diagnosis_chain.invoke({
            "topic": topic,
            "research_type": research_type
        }).content
        
        return {"analysis": result}
    except Exception as e:
        print(f"é€‰é¢˜è¯Šæ–­æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return {"analysis": "è¯Šæ–­åˆ†ææš‚æ—¶æ— æ³•å®Œæˆï¼Œè¯·ç¨åé‡è¯•ã€‚"}

def analyze_topic_feasibility(topic, research_type):
    """åˆ†æé€‰é¢˜å¯è¡Œæ€§"""
    current_llm = get_llm(temperature=0.2)
    
    feasibility_template = ChatPromptTemplate.from_messages([
        ("human", """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ–°é—»ä¼ æ’­å­¦æ•™æˆï¼Œè¯·å¯¹ä»¥ä¸‹é€‰é¢˜è¿›è¡Œå¯è¡Œæ€§è¯„åˆ†å’Œåˆ†æã€‚

ç ”ç©¶ä¸»é¢˜ï¼š{topic}
ç ”ç©¶ç±»å‹ï¼š{research_type}

è¯·ä»ä»¥ä¸‹ç»´åº¦è¿›è¡Œè¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰å¹¶æä¾›åˆ†æï¼š

1. **ç†è®ºå¯è¡Œæ€§**ï¼šç†è®ºåŸºç¡€æ˜¯å¦æ‰å®ï¼Œç†è®ºæ¡†æ¶æ˜¯å¦æ¸…æ™°
2. **æ–¹æ³•å¯è¡Œæ€§**ï¼šç ”ç©¶æ–¹æ³•æ˜¯å¦åˆé€‚ï¼Œæ“ä½œæ˜¯å¦å¯è¡Œ
3. **æ•°æ®å¯è·å¾—æ€§**ï¼šæ•°æ®æ¥æºæ˜¯å¦å¯é ï¼Œè·å–æ˜¯å¦å®¹æ˜“
4. **åˆ›æ–°æ€§**ï¼šç ”ç©¶æ˜¯å¦æœ‰åˆ›æ–°ç‚¹ï¼Œæ˜¯å¦å¡«è¡¥ç ”ç©¶ç©ºç™½
5. **æ€»ä½“è¯„åˆ†**ï¼šç»¼åˆè€ƒè™‘æ‰€æœ‰å› ç´ çš„æ€»ä½“è¯„åˆ†

è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- theoretical_score: ç†è®ºå¯è¡Œæ€§è¯„åˆ†
- methodological_score: æ–¹æ³•å¯è¡Œæ€§è¯„åˆ†
- data_score: æ•°æ®å¯è·å¾—æ€§è¯„åˆ†
- innovation_score: åˆ›æ–°æ€§è¯„åˆ†
- score: æ€»ä½“è¯„åˆ†
- theoretical: ç†è®ºå¯è¡Œæ€§åˆ†æ
- methodological: æ–¹æ³•å¯è¡Œæ€§åˆ†æ
- data_availability: æ•°æ®å¯è·å¾—æ€§åˆ†æ
- innovation: åˆ›æ–°æ€§åˆ†æ
- suggestions: æ”¹è¿›å»ºè®®åˆ—è¡¨

è¯·ç¡®ä¿è¿”å›çš„æ˜¯æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚""")
    ])
    
    feasibility_chain = feasibility_template | current_llm
    
    try:
        result = feasibility_chain.invoke({
            "topic": topic,
            "research_type": research_type
        }).content
        
        # å°è¯•è§£æJSONç»“æœ
        try:
            # æå–JSONéƒ¨åˆ†
            json_start = result.find('{')
            json_end = result.rfind('}') + 1
            if json_start != -1 and json_end != 0:
                json_str = result[json_start:json_end]
                feasibility_data = json.loads(json_str)
            else:
                # å¦‚æœæ— æ³•è§£æJSONï¼Œç”Ÿæˆé»˜è®¤æ•°æ®
                feasibility_data = generate_default_feasibility_data()
        except json.JSONDecodeError:
            feasibility_data = generate_default_feasibility_data()
        
        return feasibility_data
    except Exception as e:
        print(f"å¯è¡Œæ€§åˆ†ææ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return generate_default_feasibility_data()

def generate_default_feasibility_data():
    """ç”Ÿæˆé»˜è®¤çš„å¯è¡Œæ€§æ•°æ®"""
    return {
        "theoretical_score": random.randint(60, 85),
        "methodological_score": random.randint(65, 90),
        "data_score": random.randint(50, 80),
        "innovation_score": random.randint(70, 95),
        "score": random.randint(65, 85),
        "theoretical": "ç†è®ºå¯è¡Œæ€§éœ€è¦è¿›ä¸€æ­¥è¯„ä¼°",
        "methodological": "æ–¹æ³•å¯è¡Œæ€§éœ€è¦å…·ä½“åˆ†æ",
        "data_availability": "æ•°æ®å¯è·å¾—æ€§éœ€è¦è°ƒç ”",
        "innovation": "åˆ›æ–°æ€§éœ€è¦ä¸ç°æœ‰ç ”ç©¶å¯¹æ¯”",
        "suggestions": [
            "å»ºè®®è¿›ä¸€æ­¥æ˜ç¡®ç ”ç©¶é—®é¢˜",
            "éœ€è¦è¡¥å……ç›¸å…³ç†è®ºåŸºç¡€",
            "å»ºè®®è°ƒç ”æ•°æ®å¯è·å¾—æ€§",
            "å¯ä»¥å¢åŠ ç ”ç©¶çš„åˆ›æ–°ç‚¹"
        ]
    }

def get_research_trends():
    """è·å–ç ”ç©¶è¶‹åŠ¿"""
    current_llm = get_llm(temperature=0.4)
    
    trends_template = ChatPromptTemplate.from_messages([
        ("human", """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ–°é—»ä¼ æ’­å­¦æ•™æˆï¼Œè¯·æ€»ç»“å½“å‰æ–°é—»ä¼ æ’­å­¦é¢†åŸŸçš„ç ”ç©¶è¶‹åŠ¿å’Œçƒ­ç‚¹è¯é¢˜ã€‚

è¯·ä»ä»¥ä¸‹æ–¹é¢è¿›è¡Œåˆ†æï¼š

1. **ç†è®ºç ”ç©¶è¶‹åŠ¿**
   - æ–°å…´ç†è®ºå‘å±•
   - ç»å…¸ç†è®ºçš„æ–°åº”ç”¨
   - è·¨å­¦ç§‘ç†è®ºèåˆ

2. **æŠ€æœ¯å‘å±•å½±å“**
   - æ–°åª’ä½“æŠ€æœ¯å¯¹ä¼ æ’­çš„å½±å“
   - äººå·¥æ™ºèƒ½ä¸ä¼ æ’­ç ”ç©¶
   - ç¤¾äº¤åª’ä½“ç ”ç©¶æ–°æ–¹å‘

3. **ç¤¾ä¼šçƒ­ç‚¹è¯é¢˜**
   - å½“å‰ç¤¾ä¼šå…³æ³¨çš„ä¼ æ’­ç°è±¡
   - æ”¿ç­–å˜åŒ–å¯¹ä¼ æ’­çš„å½±å“
   - å…¨çƒåŒ–èƒŒæ™¯ä¸‹çš„ä¼ æ’­ç ”ç©¶

4. **ç ”ç©¶æ–¹æ³•åˆ›æ–°**
   - æ–°çš„ç ”ç©¶æ–¹æ³•åº”ç”¨
   - æ··åˆç ”ç©¶æ–¹æ³•å‘å±•
   - å¤§æ•°æ®åˆ†ææ–¹æ³•

è¯·æä¾›è¯¦ç»†çš„åˆ†ææŠ¥å‘Šï¼Œå¸®åŠ©ç ”ç©¶è€…äº†è§£å­¦ç§‘å‘å±•åŠ¨æ€ã€‚""")
    ])
    
    trends_chain = trends_template | current_llm
    
    try:
        result = trends_chain.invoke({}).content
        return {"trends": result}
    except Exception as e:
        print(f"è·å–ç ”ç©¶è¶‹åŠ¿æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return {"trends": "ç ”ç©¶è¶‹åŠ¿åˆ†ææš‚æ—¶æ— æ³•å®Œæˆï¼Œè¯·ç¨åé‡è¯•ã€‚"}

def intelligent_annotation(paper_content, annotation_type="comprehensive"):
    """æ™ºèƒ½æ‰¹æ³¨åŠŸèƒ½ - å¢å¼ºç‰ˆ"""
    current_llm = get_llm(temperature=0.2)
    
    # æ ¹æ®æ‰¹æ³¨ç±»å‹é€‰æ‹©ä¸åŒçš„æç¤ºè¯
    if annotation_type == "å…¨é¢æ‰¹æ³¨":
        prompt_template = get_comprehensive_annotation_prompt()
    elif annotation_type == "å­¦æœ¯è§„èŒƒæ€§":
        prompt_template = get_academic_standard_prompt()
    elif annotation_type == "é€»è¾‘ç»“æ„":
        prompt_template = get_logic_structure_prompt()
    elif annotation_type == "å†…å®¹è´¨é‡":
        prompt_template = get_content_quality_prompt()
    elif annotation_type == "è¯­è¨€è¡¨è¾¾":
        prompt_template = get_language_expression_prompt()
    else:
        prompt_template = get_comprehensive_annotation_prompt()
    
    annotation_chain = prompt_template | current_llm
    
    try:
        result = annotation_chain.invoke({
            "paper_content": paper_content,
            "annotation_type": annotation_type
        }).content
        
        return {"annotation": result}
    except Exception as e:
        print(f"æ™ºèƒ½æ‰¹æ³¨æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return {"annotation": "æ‰¹æ³¨åˆ†ææš‚æ—¶æ— æ³•å®Œæˆï¼Œè¯·ç¨åé‡è¯•ã€‚"}

def get_comprehensive_annotation_prompt():
    """è·å–å…¨é¢æ‰¹æ³¨æç¤ºè¯"""
    return ChatPromptTemplate.from_messages([
        ("human", """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ–°é—»ä¼ æ’­å­¦æ•™æˆï¼Œæ‹¥æœ‰20å¹´ä»¥ä¸Šçš„å­¦æœ¯ç ”ç©¶ç»éªŒã€‚è¯·å¯¹ä»¥ä¸‹è®ºæ–‡å†…å®¹è¿›è¡Œæ·±åº¦ä¸“ä¸šæ‰¹æ³¨ã€‚

è®ºæ–‡å†…å®¹ï¼š{paper_content}

è¯·ä»ä»¥ä¸‹**10ä¸ªä¸“ä¸šç»´åº¦**è¿›è¡Œè¯¦ç»†æ‰¹æ³¨ï¼š

## ğŸ“‹ **1. å­¦æœ¯è§„èŒƒæ€§è¯„ä¼°**
- **å¼•ç”¨æ ¼å¼**ï¼šæ£€æŸ¥APA/MLA/GBæ ¼å¼è§„èŒƒæ€§
- **å‚è€ƒæ–‡çŒ®**ï¼šå®Œæ•´æ€§ã€å‡†ç¡®æ€§ã€æ—¶æ•ˆæ€§
- **å­¦æœ¯è¡¨è¾¾**ï¼šé¿å…å£è¯­åŒ–ã€ä½¿ç”¨ç¬¬ä¸‰äººç§°
- **æ ¼å¼è§„èŒƒ**ï¼šæ ‡é¢˜ã€æ®µè½ã€å›¾è¡¨æ ¼å¼

## ğŸ§  **2. ç†è®ºæ¡†æ¶åˆ†æ**
- **ç†è®ºåŸºç¡€**ï¼šæ˜¯å¦è¿ç”¨äº†åˆé€‚çš„ä¼ æ’­å­¦ç†è®º
- **ç†è®ºåˆ›æ–°**ï¼šæ˜¯å¦æœ‰ç†è®ºè´¡çŒ®æˆ–åˆ›æ–°ç‚¹
- **ç†è®ºåº”ç”¨**ï¼šç†è®ºè¿ç”¨æ˜¯å¦æ°å½“ã€æ·±å…¥
- **ç†è®ºå¯¹è¯**ï¼šæ˜¯å¦ä¸ç°æœ‰ç†è®ºå½¢æˆå¯¹è¯

## ğŸ”¬ **3. ç ”ç©¶æ–¹æ³•è¯„ä¼°**
- **æ–¹æ³•é€‰æ‹©**ï¼šå®šé‡/å®šæ€§/æ··åˆæ–¹æ³•æ˜¯å¦åˆé€‚
- **ç ”ç©¶è®¾è®¡**ï¼šå®éªŒè®¾è®¡ã€è°ƒæŸ¥è®¾è®¡ã€æ¡ˆä¾‹ç ”ç©¶è®¾è®¡
- **æ•°æ®æ”¶é›†**ï¼šæ ·æœ¬é€‰æ‹©ã€æ•°æ®æ¥æºã€æ”¶é›†æ–¹æ³•
- **æ•°æ®åˆ†æ**ï¼šç»Ÿè®¡æ–¹æ³•ã€åˆ†æå·¥å…·ã€ç»“æœè§£é‡Š

## ğŸ“Š **4. é€»è¾‘ç»“æ„åˆ†æ**
- **è®ºè¯é€»è¾‘**ï¼šå‰æ-æ¨ç†-ç»“è®ºçš„é€»è¾‘é“¾æ¡
- **ç»“æ„å®Œæ•´æ€§**ï¼šå¼•è¨€-æ–‡çŒ®ç»¼è¿°-æ–¹æ³•-ç»“æœ-è®¨è®º-ç»“è®º
- **æ®µè½ç»„ç»‡**ï¼šæ®µè½é—´çš„é€»è¾‘å…³ç³»
- **è¿‡æ¸¡è¿æ¥**ï¼šæ®µè½é—´çš„è¿‡æ¸¡æ˜¯å¦è‡ªç„¶

## ğŸ’¡ **5. åˆ›æ–°æ€§è¯„ä¼°**
- **ç ”ç©¶é—®é¢˜**ï¼šé—®é¢˜çš„æ–°é¢–æ€§å’Œé‡è¦æ€§
- **ç ”ç©¶è§†è§’**ï¼šæ˜¯å¦æä¾›äº†æ–°çš„ç ”ç©¶è§†è§’
- **ç ”ç©¶å‘ç°**ï¼šæ˜¯å¦æœ‰æ–°çš„å‘ç°æˆ–è§è§£
- **å®è·µä»·å€¼**ï¼šå¯¹æ–°é—»ä¼ æ’­å®è·µçš„æŒ‡å¯¼æ„ä¹‰

## ğŸ¯ **6. å†…å®¹è´¨é‡åˆ†æ**
- **ç ”ç©¶æ·±åº¦**ï¼šåˆ†æçš„æ·±åº¦å’Œå¹¿åº¦
- **è®ºè¯å……åˆ†æ€§**ï¼šè®ºæ®æ˜¯å¦å……åˆ†ã€æœ‰åŠ›
- **ç»“è®ºå¯é æ€§**ï¼šç»“è®ºæ˜¯å¦åŸºäºå……åˆ†è¯æ®
- **å±€é™æ€§è®¤è¯†**ï¼šæ˜¯å¦è®¤è¯†åˆ°ç ”ç©¶å±€é™æ€§

## âœï¸ **7. è¯­è¨€è¡¨è¾¾è¯„ä¼°**
- **å­¦æœ¯è¯­è¨€**ï¼šä½¿ç”¨è§„èŒƒçš„å­¦æœ¯è¡¨è¾¾
- **è¡¨è¾¾æ¸…æ™°åº¦**ï¼šæ¦‚å¿µè¡¨è¾¾æ˜¯å¦æ¸…æ™°å‡†ç¡®
- **ä¸“ä¸šæœ¯è¯­**ï¼šæœ¯è¯­ä½¿ç”¨æ˜¯å¦å‡†ç¡®æ°å½“
- **è¯­è¨€æµç•…æ€§**ï¼šè¡¨è¾¾æ˜¯å¦æµç•…è‡ªç„¶

## ğŸ“ˆ **8. å®è¯ç ”ç©¶ç‰¹è‰²**ï¼ˆå¦‚é€‚ç”¨ï¼‰
- **æ•°æ®è´¨é‡**ï¼šæ•°æ®çš„å¯é æ€§ã€æœ‰æ•ˆæ€§
- **åˆ†ææ·±åº¦**ï¼šç»Ÿè®¡åˆ†æçš„æ·±åº¦å’Œå‡†ç¡®æ€§
- **ç»“æœè§£é‡Š**ï¼šå¯¹ç»“æœçš„åˆç†è§£é‡Š
- **å®è·µåº”ç”¨**ï¼šç ”ç©¶ç»“æœçš„å®è·µæŒ‡å¯¼ä»·å€¼

## ğŸŒ **9. æ–°é—»ä¼ æ’­å­¦ä¸“ä¸šç‰¹è‰²**
- **å­¦ç§‘å‰æ²¿**ï¼šæ˜¯å¦æ¶‰åŠå­¦ç§‘å‰æ²¿é—®é¢˜
- **è¡Œä¸šå…³è”**ï¼šä¸æ–°é—»ä¼ æ’­è¡Œä¸šçš„å…³è”åº¦
- **ç¤¾ä¼šä»·å€¼**ï¼šå¯¹ç¤¾ä¼šå‘å±•çš„è´¡çŒ®
- **å›½é™…è§†é‡**ï¼šæ˜¯å¦å…·æœ‰å›½é™…æ¯”è¾ƒè§†é‡

## ğŸ”§ **10. å…·ä½“æ”¹è¿›å»ºè®®**
- **ç»“æ„ä¼˜åŒ–**ï¼šå…·ä½“çš„ç»“æ„è°ƒæ•´å»ºè®®
- **å†…å®¹è¡¥å……**ï¼šéœ€è¦è¡¥å……çš„å†…å®¹å’Œæ–¹å‘
- **æ–¹æ³•æ”¹è¿›**ï¼šç ”ç©¶æ–¹æ³•çš„æ”¹è¿›å»ºè®®
- **è¡¨è¾¾ä¼˜åŒ–**ï¼šè¯­è¨€è¡¨è¾¾çš„æ”¹è¿›å»ºè®®

è¯·ä¸ºæ¯ä¸ªç»´åº¦æä¾›ï¼š
1. **å…·ä½“é—®é¢˜è¯†åˆ«**ï¼šæŒ‡å‡ºå…·ä½“å­˜åœ¨çš„é—®é¢˜
2. **ä¸“ä¸šåˆ†æ**ï¼šä»æ–°é—»ä¼ æ’­å­¦ä¸“ä¸šè§’åº¦åˆ†æ
3. **æ”¹è¿›å»ºè®®**ï¼šæä¾›å…·ä½“ã€å¯æ“ä½œçš„æ”¹è¿›å»ºè®®
4. **è¯„åˆ†**ï¼šæ¯ä¸ªç»´åº¦ç»™å‡º1-10åˆ†çš„è¯„åˆ†

æœ€åæä¾›**æ€»ä½“è¯„ä»·**å’Œ**ä¼˜å…ˆçº§æ”¹è¿›å»ºè®®**ã€‚

è¯·ç¡®ä¿æ‰¹æ³¨ä¸“ä¸šã€å…·ä½“ã€å¯æ“ä½œï¼Œä½“ç°æ–°é—»ä¼ æ’­å­¦çš„ä¸“ä¸šç‰¹è‰²ã€‚""")
    ])

def get_academic_standard_prompt():
    """è·å–å­¦æœ¯è§„èŒƒæ€§æ‰¹æ³¨æç¤ºè¯"""
    return ChatPromptTemplate.from_messages([
        ("human", """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ–°é—»ä¼ æ’­å­¦æ•™æˆï¼Œè¯·ä¸“é—¨é’ˆå¯¹å­¦æœ¯è§„èŒƒæ€§å¯¹ä»¥ä¸‹è®ºæ–‡å†…å®¹è¿›è¡Œæ‰¹æ³¨ã€‚

è®ºæ–‡å†…å®¹ï¼š{paper_content}

è¯·é‡ç‚¹æ£€æŸ¥ä»¥ä¸‹æ–¹é¢ï¼š

## ğŸ“š **å¼•ç”¨æ ¼å¼è§„èŒƒ**
- æ–‡å†…å¼•ç”¨æ ¼å¼ï¼ˆä½œè€…-å¹´ä»½/æ•°å­—ç¼–å·ï¼‰
- å‚è€ƒæ–‡çŒ®åˆ—è¡¨æ ¼å¼
- å¼•ç”¨å®Œæ•´æ€§ï¼ˆä½œè€…ã€å¹´ä»½ã€æ ‡é¢˜ã€æ¥æºï¼‰
- å¼•ç”¨æ—¶æ•ˆæ€§ï¼ˆæ–‡çŒ®çš„æ–°æ—§ç¨‹åº¦ï¼‰

## ğŸ“ **å­¦æœ¯è¡¨è¾¾è§„èŒƒ**
- é¿å…ç¬¬ä¸€äººç§°ï¼ˆæˆ‘ã€æˆ‘ä»¬ï¼‰
- ä½¿ç”¨å®¢è§‚ã€æ­£å¼çš„å­¦æœ¯è¯­è¨€
- é¿å…å£è¯­åŒ–è¡¨è¾¾
- ä½¿ç”¨é€‚å½“çš„å­¦æœ¯è¿æ¥è¯

## ğŸ“‹ **æ ¼å¼è§„èŒƒ**
- æ ‡é¢˜æ ¼å¼å’Œå±‚çº§
- æ®µè½æ ¼å¼å’Œç¼©è¿›
- å›¾è¡¨æ ‡é¢˜å’Œç¼–å·
- é¡µçœ‰é¡µè„šæ ¼å¼

## ğŸ” **ä¸“ä¸šæœ¯è¯­ä½¿ç”¨**
- æ–°é—»ä¼ æ’­å­¦ä¸“ä¸šæœ¯è¯­çš„å‡†ç¡®æ€§
- æœ¯è¯­ä½¿ç”¨çš„ä¸€è‡´æ€§
- æ–°æ¦‚å¿µçš„å®šä¹‰å’Œè§£é‡Š

è¯·æä¾›å…·ä½“çš„ä¿®æ”¹å»ºè®®å’Œç¤ºä¾‹ã€‚""")
    ])

def get_logic_structure_prompt():
    """è·å–é€»è¾‘ç»“æ„æ‰¹æ³¨æç¤ºè¯"""
    return ChatPromptTemplate.from_messages([
        ("human", """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ–°é—»ä¼ æ’­å­¦æ•™æˆï¼Œè¯·ä¸“é—¨é’ˆå¯¹é€»è¾‘ç»“æ„å¯¹ä»¥ä¸‹è®ºæ–‡å†…å®¹è¿›è¡Œæ‰¹æ³¨ã€‚

è®ºæ–‡å†…å®¹ï¼š{paper_content}

è¯·é‡ç‚¹åˆ†æä»¥ä¸‹æ–¹é¢ï¼š

## ğŸ—ï¸ **æ•´ä½“ç»“æ„**
- è®ºæ–‡å„éƒ¨åˆ†æ˜¯å¦å®Œæ•´
- å„éƒ¨åˆ†ä¹‹é—´çš„é€»è¾‘å…³ç³»
- ç»“æ„æ˜¯å¦ç¬¦åˆå­¦æœ¯è§„èŒƒ

## ğŸ”— **è®ºè¯é€»è¾‘**
- å‰ææ˜¯å¦æ˜ç¡®
- æ¨ç†è¿‡ç¨‹æ˜¯å¦åˆç†
- ç»“è®ºæ˜¯å¦åŸºäºå……åˆ†è¯æ®
- é€»è¾‘é“¾æ¡æ˜¯å¦å®Œæ•´

## ğŸ“‘ **æ®µè½ç»„ç»‡**
- æ®µè½ä¸»é¢˜æ˜¯å¦æ˜ç¡®
- æ®µè½é—´è¿‡æ¸¡æ˜¯å¦è‡ªç„¶
- æ®µè½å†…å®¹æ˜¯å¦å›´ç»•ä¸»é¢˜

## ğŸ¯ **é‡ç‚¹çªå‡º**
- æ ¸å¿ƒè§‚ç‚¹æ˜¯å¦çªå‡º
- é‡è¦å‘ç°æ˜¯å¦å¼ºè°ƒ
- ç ”ç©¶è´¡çŒ®æ˜¯å¦æ˜ç¡®

è¯·æä¾›å…·ä½“çš„ç»“æ„è°ƒæ•´å»ºè®®ã€‚""")
    ])

def get_content_quality_prompt():
    """è·å–å†…å®¹è´¨é‡æ‰¹æ³¨æç¤ºè¯"""
    return ChatPromptTemplate.from_messages([
        ("human", """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ–°é—»ä¼ æ’­å­¦æ•™æˆï¼Œè¯·ä¸“é—¨é’ˆå¯¹å†…å®¹è´¨é‡å¯¹ä»¥ä¸‹è®ºæ–‡å†…å®¹è¿›è¡Œæ‰¹æ³¨ã€‚

è®ºæ–‡å†…å®¹ï¼š{paper_content}

è¯·é‡ç‚¹è¯„ä¼°ä»¥ä¸‹æ–¹é¢ï¼š

## ğŸ§  **ç†è®ºæ·±åº¦**
- ç†è®ºè¿ç”¨æ˜¯å¦æ°å½“
- ç†è®ºåˆ†ææ˜¯å¦æ·±å…¥
- æ˜¯å¦æœ‰ç†è®ºåˆ›æ–°

## ğŸ”¬ **ç ”ç©¶æ·±åº¦**
- é—®é¢˜åˆ†ææ˜¯å¦æ·±å…¥
- è®ºè¯æ˜¯å¦å……åˆ†
- ç»“è®ºæ˜¯å¦å¯é 

## ğŸ“Š **å®è¯è´¨é‡**ï¼ˆå¦‚é€‚ç”¨ï¼‰
- æ•°æ®è´¨é‡å¦‚ä½•
- åˆ†ææ–¹æ³•æ˜¯å¦åˆé€‚
- ç»“æœè§£é‡Šæ˜¯å¦åˆç†

## ğŸ’¡ **åˆ›æ–°æ€§**
- ç ”ç©¶é—®é¢˜æ˜¯å¦æ–°é¢–
- ç ”ç©¶æ–¹æ³•æ˜¯å¦æœ‰åˆ›æ–°
- ç ”ç©¶ç»“æœæ˜¯å¦æœ‰æ–°å‘ç°

## ğŸŒ **å®è·µä»·å€¼**
- å¯¹æ–°é—»ä¼ æ’­å®è·µçš„æŒ‡å¯¼æ„ä¹‰
- å¯¹ç¤¾ä¼šå‘å±•çš„è´¡çŒ®
- å¯¹å­¦ç§‘å‘å±•çš„æ¨åŠ¨

è¯·æä¾›å…·ä½“çš„å†…å®¹æ”¹è¿›å»ºè®®ã€‚""")
    ])

def get_language_expression_prompt():
    """è·å–è¯­è¨€è¡¨è¾¾æ‰¹æ³¨æç¤ºè¯"""
    return ChatPromptTemplate.from_messages([
        ("human", """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ–°é—»ä¼ æ’­å­¦æ•™æˆï¼Œè¯·ä¸“é—¨é’ˆå¯¹è¯­è¨€è¡¨è¾¾å¯¹ä»¥ä¸‹è®ºæ–‡å†…å®¹è¿›è¡Œæ‰¹æ³¨ã€‚

è®ºæ–‡å†…å®¹ï¼š{paper_content}

è¯·é‡ç‚¹æ£€æŸ¥ä»¥ä¸‹æ–¹é¢ï¼š

## âœï¸ **è¯­è¨€è§„èŒƒæ€§**
- è¯­æ³•æ˜¯å¦æ­£ç¡®
- ç”¨è¯æ˜¯å¦å‡†ç¡®
- å¥å¼æ˜¯å¦å¤šæ ·
- è¡¨è¾¾æ˜¯å¦ç®€æ´

## ğŸ¯ **è¡¨è¾¾æ¸…æ™°åº¦**
- æ¦‚å¿µè¡¨è¾¾æ˜¯å¦æ¸…æ™°
- é€»è¾‘å…³ç³»æ˜¯å¦æ˜ç¡®
- é‡ç‚¹æ˜¯å¦çªå‡º
- è¯­è¨€æ˜¯å¦æµç•…

## ğŸ“š **å­¦æœ¯è¯­è¨€**
- æ˜¯å¦ä½¿ç”¨è§„èŒƒçš„å­¦æœ¯è¡¨è¾¾
- ä¸“ä¸šæœ¯è¯­ä½¿ç”¨æ˜¯å¦å‡†ç¡®
- è¯­è¨€é£æ ¼æ˜¯å¦ä¸€è‡´
- æ˜¯å¦é¿å…å£è¯­åŒ–

## ğŸ”— **è¯­è¨€è¿è´¯æ€§**
- å¥å­é—´è¿æ¥æ˜¯å¦è‡ªç„¶
- æ®µè½é—´è¿‡æ¸¡æ˜¯å¦æµç•…
- æ•´ä½“è¯­è¨€é£æ ¼æ˜¯å¦ç»Ÿä¸€

è¯·æä¾›å…·ä½“çš„è¯­è¨€ä¿®æ”¹å»ºè®®å’Œç¤ºä¾‹ã€‚""")
    ])

def format_correction(paper_content, target_format="APA"):
    """æ ¼å¼ä¿®æ­£åŠŸèƒ½"""
    current_llm = get_llm(temperature=0.1)
    
    format_template = ChatPromptTemplate.from_messages([
        ("human", """ä½ æ˜¯ä¸€ä½èµ„æ·±çš„å­¦æœ¯ç¼–è¾‘ï¼Œè¯·å¯¹ä»¥ä¸‹è®ºæ–‡å†…å®¹è¿›è¡Œæ ¼å¼ä¿®æ­£ã€‚

è®ºæ–‡å†…å®¹ï¼š{paper_content}
ç›®æ ‡æ ¼å¼ï¼š{target_format}

è¯·è¿›è¡Œä»¥ä¸‹æ ¼å¼ä¿®æ­£ï¼š

1. **æ ‡é¢˜æ ¼å¼**
   - æ ‡é¢˜å±‚çº§è§„èŒƒ
   - å­—ä½“æ ¼å¼ç»Ÿä¸€
   - ç¼–å·æ ¼å¼è§„èŒƒ

2. **æ®µè½æ ¼å¼**
   - æ®µè½é—´è·ç»Ÿä¸€
   - ç¼©è¿›æ ¼å¼è§„èŒƒ
   - å¯¹é½æ–¹å¼ç»Ÿä¸€

3. **å¼•ç”¨æ ¼å¼**
   - å¼•ç”¨æ ¼å¼æ ‡å‡†åŒ–
   - å‚è€ƒæ–‡çŒ®æ ¼å¼è§„èŒƒ
   - å¼•ç”¨æ ‡è®°ç»Ÿä¸€

4. **å›¾è¡¨æ ¼å¼**
   - å›¾è¡¨æ ‡é¢˜è§„èŒƒ
   - å›¾è¡¨ç¼–å·ç»Ÿä¸€
   - å›¾è¡¨è¯´æ˜æ ¼å¼

5. **å…¶ä»–æ ¼å¼**
   - é¡µç æ ¼å¼
   - é¡µçœ‰é¡µè„š
   - å­—ä½“å­—å·

è¯·æä¾›ä¿®æ­£åçš„å†…å®¹ï¼Œç¡®ä¿æ ¼å¼è§„èŒƒç»Ÿä¸€ã€‚""")
    ])
    
    format_chain = format_template | current_llm
    
    try:
        result = format_chain.invoke({
            "paper_content": paper_content,
            "target_format": target_format
        }).content
        
        return {"corrected_content": result}
    except Exception as e:
        print(f"æ ¼å¼ä¿®æ­£æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return {"corrected_content": "æ ¼å¼ä¿®æ­£æš‚æ—¶æ— æ³•å®Œæˆï¼Œè¯·ç¨åé‡è¯•ã€‚"}

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    try:
        title, abstract, outline = generate_paper("å…ƒå®‡å®™ä¸æ•°å­—èº«ä»½è®¤åŒ", 0.8, 0.7)
        if title:
            print("è®ºæ–‡æ ‡é¢˜:", title)
            print("\nè®ºæ–‡ç ”ç©¶å»ºè®®:", abstract)
            if outline:
                print("\nè®ºæ–‡å¤§çº²:", outline)
        else:
            print("ç”Ÿæˆå¤±è´¥")
    except Exception as e:
        print(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")